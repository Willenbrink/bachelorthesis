\chapter{Preliminaries}
\section{First-Order Logic}
First-order logic is a formal language used to, amongst others, formalise reasoning, including artifical intelligence, logic programming and automated deduction systems. In this thesis we are only interested in terms. Therefore, we disregard formulas, relations and quantifiers.

A term in first-order logic is either a variable, a constant or a function applied to some arguments. All symbols have arity $0$. A function $f$ has a fixed arity $a(f) \geq 1$ and is applied to an $a(f)$-tuple of terms. We notate terms with lower-case letters with constants using letters from $a$ to $e$, functions from $f$ to $j$ and variables from $u$ to $z$.

\subsection{Unification}
\todo{}

\section{Isabelle}
Isabelle is an interactive theorem prover supporting many formal theories, including first-order and higher-order logics. The basic datatype used for terms are a variant of typed \lam -calculus. Therefore, encoding first-order logic terms in the applicative \lam -calculus becomes necessary.\footnote{We disregard types as we assume the user of the index to only store consistent and type-correct terms}

The prover in Isabelle repeatedly uses unification to advance the proof. It starts with a goal, whose validity must be shown, and a list of inference rules, given as horn clauses, i.e. consisting of a conjunction of premises and a conclusion. The prover now continually attempts to unify the goal with the conclusion of one of the inference rules. If successful, it replaces the goal with the premises, each of which represent a subgoal.

Upon showing the validity of each subgoal the prover is finished. If no further unification is possible the algorithm backtracks and attempts to continue with a different inference rule. Depending on the number and form of inference rules available the prover will at some point either fail to satisfy the goal or continue searching forever. Tuning the prover to provide a proof while also avoiding both failure states is one of the major challenges in automated theorem proving.\cite{paulson_isabelle_nodate}

\subsection{Term Representation in Isabelle}

A \lam -term in Isabelle is defined recursively in an applicate style. The different constructors are:
\begin{enumerate}
  \item Free: Symbols that can not be instantiated.
  \item Const: Symbols that are instantiated once and therefore are, within a given context, constant.
  \item Var: Variables that have not been instantiated.
  \item Abs and Bound: Abstractions, or \lam -expression, instantiate the symbols bound to them with the argument they are applied to. A bound symbol stores a reference to the abstraction it is bound to.
  \item App: Applications apply their first argument to the second argument. We use \$ as an infix operator.
\end{enumerate}
For example, the \lam -term $(\lambda x. f(x)) c$ can be encoded as $App(Abs(x,App(Free(f),Bound(x))),Const(c))$.\todo{Draw as tree, too many braces}

Using this datatype, we can embed first-order terms in \lam -terms. A constant $c$ is equivalent to $Const(c)$. Likewise, a variable $x$ is equivalent to $Var(x)$. Functions are written in the applicative form, e.g. $f(x,c)$ is encoded as $Const(f)\ \$\ Var(x)\ \$\ Const(c)$.

Obviously, this embedding is not invertible. Nevertheless, it is desirable for term indices to handle higher-order logic terms gracefully. We therefore \todo{}

\section{Term Indexing}
\todo{Motivation, move elsewhere?}
In automated theorem proving there are, generally, many inference rules are available while only few are applicable to the current subgoals. Therefore, we are interested in efficient storage of inference rules, both in regards to memory consumption and fast retrieval of rules with unifiable premises. One category of data structures fit for this purpose are the term indices.

A term index efficiently stores terms while also providing efficient operations for the retrieval of instances, generalisations and unifiables of a query term from the term index. Depending on the exact data structure, we can also implement other operations efficiently if desired, e.g. checking if a term is already stored, only inserting a term if no more general term is stored, efficiently merging two indices etc.

As it is difficult to predict the use cases of the term indices we only implement the basic query operations. \todo{already implemented for the discrimination nets}

\section{Related work}
